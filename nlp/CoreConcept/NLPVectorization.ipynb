{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qviBJSLBm0wV"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpustext= [\"The king ruled his kingdom with wisdom and justice\",\n",
        "    \"The queen was beloved by all her subjects\",\n",
        "    \"A man walked through the busy streets of the city\",\n",
        "    \"The woman opened her book and began to read\",\n",
        "    \"The cat sat quietly on the windowsill watching birds\",\n",
        "    \"A dog barked loudly in the neighbor's yard\",\n",
        "    \"Paris is the capital city of France\",\n",
        "    \"Rome is known for its ancient history and architecture\",\n",
        "    \"Italy has beautiful landscapes and delicious food\",\n",
        "    \"France is famous for its wine and cuisine\",\n",
        "    \"The doctor examined the patient carefully\",\n",
        "    \"The teacher explained the lesson to her students\",\n",
        "    \"Computer science involves programming and algorithms\",\n",
        "    \"Machine learning is a subset of artificial intelligence\",\n",
        "    \"Python is a popular programming language\",\n",
        "    \"Data science combines statistics and programming\",\n",
        "    \"The sun shines brightly in the clear blue sky\",\n",
        "    \"Rain falls gently on the green grass\",\n",
        "    \"Mountains rise majestically above the valley\",\n",
        "    \"The ocean waves crash against the rocky shore.\"]"
      ],
      "metadata": {
        "id": "MJd9r5E_nGkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpustext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSfqCIUnne8K",
        "outputId": "a82962e3-b795-406b-d9fd-84cdb53dab3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The cat sat on the mat,', 'The dog sat on the log', 'Cats and dogs are great pets.', 'I have cat, I have Dog.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words(BOW)**"
      ],
      "metadata": {
        "id": "qdZsxdBVsoxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X= vectorizer.fit_transform(corpustext)"
      ],
      "metadata": {
        "id": "0JhG-iBcsf2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXBpu7bhs-Hj",
        "outputId": "9536dd37-ff76-4bde-9d01-fc5826a4b87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and' 'are' 'cat' 'cats' 'dog' 'dogs' 'great' 'have' 'log' 'mat' 'on'\n",
            " 'pets' 'sat' 'the']\n",
            "[[0 0 1 0 0 0 0 0 0 1 1 0 1 2]\n",
            " [0 0 0 0 1 0 0 0 1 0 1 0 1 2]\n",
            " [1 1 0 1 0 1 1 0 0 0 0 1 0 0]\n",
            " [0 0 1 0 1 0 0 2 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the above output each row of matrix corresponds to one document and each document corresponds to a unique word in the corpus. The value of each cell is the count of the word in the in the document.**"
      ],
      "metadata": {
        "id": "dxsClhA5t9MR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Term Frequency-Inverse Document Frequencey**\n"
      ],
      "metadata": {
        "id": "rVDgXY_gujp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "BCv_LlEdurkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X= vectorizer.fit_transform(corpustext)"
      ],
      "metadata": {
        "id": "abTMky-LvGOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnLTDDjCvLcs",
        "outputId": "bd877495-d577-4234-b13f-621f423188dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and' 'are' 'cat' 'cats' 'dog' 'dogs' 'great' 'have' 'log' 'mat' 'on'\n",
            " 'pets' 'sat' 'the']\n",
            "[[0.         0.         0.34082342 0.         0.         0.\n",
            "  0.         0.         0.         0.43229129 0.34082342 0.\n",
            "  0.34082342 0.68164684]\n",
            " [0.         0.         0.         0.         0.34082342 0.\n",
            "  0.         0.         0.43229129 0.         0.34082342 0.\n",
            "  0.34082342 0.68164684]\n",
            " [0.40824829 0.40824829 0.         0.40824829 0.         0.40824829\n",
            "  0.40824829 0.         0.         0.         0.         0.40824829\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.34431452 0.         0.34431452 0.\n",
            "  0.         0.87343862 0.         0.         0.         0.\n",
            "  0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The aboove reult contains TF-IDF scores instead of word count."
      ],
      "metadata": {
        "id": "5Q5FsL_SvfSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2Vec**"
      ],
      "metadata": {
        "id": "U8u24vgrv1Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zn3DHvbv8X0",
        "outputId": "3e6ac07a-9610-4e88-ae3d-bebf7c51d502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "uIhVXNqvwveT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8rCv3u5w0_a",
        "outputId": "4d89e56e-8f33-4448-8db0-a71fdd8a6857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordtoken = [word_tokenize(sent) for sent in corpustext]"
      ],
      "metadata": {
        "id": "5-XhuHmlw6kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wordtoken)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5piQLzK-xsRJ",
        "outputId": "b89dbfaf-51e9-43b4-b1c2-56481519dca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['The', 'king', 'ruled', 'his', 'kingdom', 'with', 'wisdom', 'and', 'justice'], ['The', 'queen', 'was', 'beloved', 'by', 'all', 'her', 'subjects'], ['A', 'man', 'walked', 'through', 'the', 'busy', 'streets', 'of', 'the', 'city'], ['The', 'woman', 'opened', 'her', 'book', 'and', 'began', 'to', 'read'], ['The', 'cat', 'sat', 'quietly', 'on', 'the', 'windowsill', 'watching', 'birds'], ['A', 'dog', 'barked', 'loudly', 'in', 'the', 'neighbor', \"'s\", 'yard'], ['Paris', 'is', 'the', 'capital', 'city', 'of', 'France'], ['Rome', 'is', 'known', 'for', 'its', 'ancient', 'history', 'and', 'architecture'], ['Italy', 'has', 'beautiful', 'landscapes', 'and', 'delicious', 'food'], ['France', 'is', 'famous', 'for', 'its', 'wine', 'and', 'cuisine'], ['The', 'doctor', 'examined', 'the', 'patient', 'carefully'], ['The', 'teacher', 'explained', 'the', 'lesson', 'to', 'her', 'students'], ['Computer', 'science', 'involves', 'programming', 'and', 'algorithms'], ['Machine', 'learning', 'is', 'a', 'subset', 'of', 'artificial', 'intelligence'], ['Python', 'is', 'a', 'popular', 'programming', 'language'], ['Data', 'science', 'combines', 'statistics', 'and', 'programming'], ['The', 'sun', 'shines', 'brightly', 'in', 'the', 'clear', 'blue', 'sky'], ['Rain', 'falls', 'gently', 'on', 'the', 'green', 'grass'], ['Mountains', 'rise', 'majestically', 'above', 'the', 'valley'], ['The', 'ocean', 'waves', 'crash', 'against', 'the', 'rocky', 'shore', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Word2Vec model\n",
        "model= Word2Vec(wordtoken, min_count=1)"
      ],
      "metadata": {
        "id": "x1FJf9q-x-pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwH6Ga6xyKYx",
        "outputId": "cbac2182-0278-4302-882d-6bce6dd121b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=113, vector_size=100, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocabulary size: {len(model.wv.key_to_index)}\")\n",
        "print(f\"Vector size: {model.vector_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KTj-Dm55Pdb",
        "outputId": "8ace380b-51f3-4b68-caf9-ea9ba2595730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 113\n",
            "Vector size: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Explore word embeddings\n",
        "print(\"\\n=== Word Embedding Examples ===\")\n",
        "\n",
        "# Get vector for a specific word\n",
        "word = \"King\"\n",
        "if word in model.wv:\n",
        "    vector = model.wv[word]\n",
        "    print(f\"Vector for '{word}' (first 10 dimensions): {vector[:10]}\")\n",
        "\n",
        "# Find similar words\n",
        "print(f\"\\nWords similar to 'King':\")\n",
        "try:\n",
        "    similar_words = model.wv.most_similar('King', topn=5)\n",
        "    for word, similarity in similar_words:\n",
        "        print(f\"  {word}: {similarity:.3f}\")\n",
        "except KeyError:\n",
        "    print(\"  'king' not found in vocabulary\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ny4rbVr5bs0",
        "outputId": "dcd8ed63-1648-4d0f-82c4-d7414931ed43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Word Embedding Examples ===\n",
            "\n",
            "Words similar to 'King':\n",
            "  'king' not found in vocabulary\n"
          ]
        }
      ]
    }
  ]
}